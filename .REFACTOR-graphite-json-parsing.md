# Refactoring: Centralize Graphite JSON Parsing

## Problem Statement

Duplicate try/except blocks for reading Graphite JSON files exist in `graphite_ops.py`:

- `get_prs_from_graphite()` lines 244-258
- `get_all_branches()` lines 274-299

Additionally, multiple locations read Graphite JSON files without error handling and will crash on malformed JSON:

- `src/workstack/cli/tree.py:192`
- `src/workstack/cli/commands/remove.py:85`
- `src/workstack/cli/commands/remove.py:194`

## Solution: Centralized Helper Function

Create a single helper function in `graphite_ops.py` that all code paths use.

### Implementation Steps

#### 1. Add helper function to `graphite_ops.py`

**Location:** After imports (line ~20), before `parse_graphite_pr_info()`

**Function signature:**

```python
def read_graphite_json_file(file_path: Path, description: str) -> dict[str, Any] | None:
    """Read and parse a Graphite JSON file with error handling.

    Args:
        file_path: Path to the JSON file
        description: Human-readable description for error messages (e.g., "Graphite cache", "Graphite PR info")

    Returns:
        Parsed JSON dict, or None if file doesn't exist or error occurs

    Note:
        Emits warnings for parse/read errors to inform user of cache issues
        without crashing the application.
    """
    if not file_path.exists():
        return None

    try:
        json_str = file_path.read_text(encoding="utf-8")
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        warnings.warn(
            f"Cannot parse {description} at {file_path}: Invalid JSON ({e})",
            stacklevel=2,
        )
        return None
    except OSError as e:
        warnings.warn(
            f"Cannot read {description} at {file_path}: {e}",
            stacklevel=2,
        )
        return None
```

**Note:** Add `from typing import Any` to imports if not already present.

#### 2. Refactor `get_prs_from_graphite()` in `graphite_ops.py` (~line 230)

**Current code (lines 240-258):**

```python
pr_info_file = git_dir / ".graphite_pr_info"
if not pr_info_file.exists():
    return {}

try:
    json_str = pr_info_file.read_text(encoding="utf-8")
    return parse_graphite_pr_info(json_str)
except json.JSONDecodeError as e:
    warnings.warn(
        f"Cannot parse Graphite PR info at {pr_info_file}: Invalid JSON ({e})",
        stacklevel=2,
    )
    return {}
except OSError as e:
    warnings.warn(
        f"Cannot read Graphite PR info at {pr_info_file}: {e}",
        stacklevel=2,
    )
    return {}
```

**Replacement:**

```python
pr_info_file = git_dir / ".graphite_pr_info"
data = read_graphite_json_file(pr_info_file, "Graphite PR info")
if data is None:
    return {}

# parse_graphite_pr_info expects JSON string, so convert back
return parse_graphite_pr_info(json.dumps(data))
```

#### 3. Refactor `get_all_branches()` in `graphite_ops.py` (~line 260)

**Current code (lines 270-299):**

```python
cache_file = git_dir / ".graphite_cache_persist"
if not cache_file.exists():
    return {}

try:
    json_str = cache_file.read_text(encoding="utf-8")
    # Get all branch heads from git for enrichment
    git_branch_heads = {}
    # This is a bit inefficient but matches original behavior
    # In reality, could be optimized by getting all refs at once
    branches_data = json.loads(json_str).get("branches", [])
    for branch_name, _ in branches_data:
        if isinstance(branch_name, str):
            commit_sha = git_ops.get_branch_head(repo_root, branch_name)
            if commit_sha:
                git_branch_heads[branch_name] = commit_sha

    return parse_graphite_cache(json_str, git_branch_heads)
except json.JSONDecodeError as e:
    warnings.warn(
        f"Cannot parse Graphite cache at {cache_file}: Invalid JSON ({e})",
        stacklevel=2,
    )
    return {}
except OSError as e:
    warnings.warn(
        f"Cannot read Graphite cache at {cache_file}: {e}",
        stacklevel=2,
    )
    return {}
```

**Replacement:**

```python
cache_file = git_dir / ".graphite_cache_persist"
data = read_graphite_json_file(cache_file, "Graphite cache")
if data is None:
    return {}

# Get all branch heads from git for enrichment
git_branch_heads = {}
branches_data = data.get("branches", [])
for branch_name, _ in branches_data:
    if isinstance(branch_name, str):
        commit_sha = git_ops.get_branch_head(repo_root, branch_name)
        if commit_sha:
            git_branch_heads[branch_name] = commit_sha

# parse_graphite_cache expects JSON string, so convert back
return parse_graphite_cache(json.dumps(data), git_branch_heads)
```

#### 4. Fix `tree.py` line 186-193

**Add import at top:**

```python
from workstack.core.graphite_ops import read_graphite_json_file
```

**Current code:**

```python
# Check if Graphite cache file exists
cache_file = git_dir / ".graphite_cache_persist"
if not cache_file.exists():
    return None

# Parse JSON
cache_data = json.loads(cache_file.read_text(encoding="utf-8"))
branches_data = cache_data.get("branches", [])
```

**Replacement:**

```python
# Check if Graphite cache file exists and parse
cache_file = git_dir / ".graphite_cache_persist"
cache_data = read_graphite_json_file(cache_file, "Graphite cache")
if cache_data is None:
    return None

branches_data = cache_data.get("branches", [])
```

#### 5. Fix `remove.py` function `_filter_trunk_branches()` line 80-86

**Add import at top:**

```python
from workstack.core.graphite_ops import read_graphite_json_file
```

**Current code:**

```python
cache_file = git_dir / ".graphite_cache_persist"
if not cache_file.exists():
    click.echo("Warning: Graphite cache not found. Cannot delete stack.", err=True)
    return []

cache_data = json.loads(cache_file.read_text(encoding="utf-8"))
branches_data = cache_data.get("branches", [])
```

**Replacement:**

```python
cache_file = git_dir / ".graphite_cache_persist"
cache_data = read_graphite_json_file(cache_file, "Graphite cache")
if cache_data is None:
    click.echo("Warning: Graphite cache not found or invalid. Cannot delete stack.", err=True)
    return []

branches_data = cache_data.get("branches", [])
```

#### 6. Fix `remove.py` in `rm()` command line ~193-196

**Current code:**

```python
cache_file = git_dir / ".graphite_cache_persist"
cache_data = json.loads(cache_file.read_text(encoding="utf-8"))
branches_data = cache_data.get("branches", [])
```

**Replacement:**

```python
cache_file = git_dir / ".graphite_cache_persist"
cache_data = read_graphite_json_file(cache_file, "Graphite cache")
if cache_data is None:
    click.echo("Warning: Graphite cache not found or invalid. Cannot determine trunk branches.", err=True)
    # Continue without filtering trunk branches - delete all requested branches
    branches_to_delete = stack
else:
    branches_data = cache_data.get("branches", [])
    # ... existing trunk filtering logic
```

**Note:** Need to read more context around line 193 to see exact integration point.

## Benefits

1. **Single source of truth** - One implementation for Graphite JSON parsing
2. **Consistent error handling** - All locations emit warnings instead of crashing
3. **Reduced duplication** - 5 implementations â†’ 1 reusable function
4. **Better user experience** - Warnings inform users of cache corruption without crashes
5. **Maintainability** - Future changes to error handling happen in one place

## Testing Considerations

- Existing tests in `tests/integration/test_graphite_ops.py` should continue to pass (behavior unchanged, just refactored)
- Tests currently expect warnings in `get_prs_from_graphite()` and `get_all_branches()`
- No existing tests for `tree.py` and `remove.py` error cases - this is an improvement (graceful degradation vs crash)

## Files Modified

1. `src/workstack/core/graphite_ops.py` - Add helper, refactor 2 methods
2. `src/workstack/cli/tree.py` - Use helper, add error handling
3. `src/workstack/cli/commands/remove.py` - Use helper in 2 locations, add error handling
