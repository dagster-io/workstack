# Implementation Plan: Enhance devrun Reporting Context

## Objective

Update the devrun agent to provide flexible, context-aware reporting back to parent agents through a reporting context parameter system. The default "minimal" context preserves current behavior, while richer contexts like "diagnostic" provide enhanced reporting with command echo, exit codes, status signals, and breakdowns tailored to the parent agent's needs.

## Context & Understanding

### Architectural Insights

**Why reporting context parameter instead of always-detailed:**

- Parent agents have different information needs depending on their use case
- Simple pass/fail checks don't need full diagnostics (token waste)
- Deep diagnostics needed when debugging failures or validating complex workflows
- Context-based approach is more semantic than just "more/less detail"
- Allows future expansion: "ci-validation", "debugging", "quick-check" without breaking changes

**Design decision: Default to minimal, not diagnostic:**

- Most devrun invocations are simple verification ("did it pass?")
- Diagnostic context adds ~50-100 tokens per report
- Parent agents explicitly request diagnostic context when they need deep analysis
- Minimal context keeps current efficient behavior as default

**Reporting context philosophy:**

- Context describes _why_ parent needs the information, not just _how much_
- Example: "for CI validation" implies need for breakdown, status signals, proceed/stop decision
- Example: "for debugging" implies need for detailed diagnostics, full error context
- Example: "for quick check" or no context implies minimal pass/fail information
- More flexible and extensible than binary minimal/diagnostic

**Status field philosophy:**

- Exit code determines base status (0 = ‚úÖ, 1+ = ‚õî)
- Fixability check adds üîß indicator when violations are auto-fixable
- Gives parent agents actionable decision: "fix manually" vs "re-run with --fix"

### Known Pitfalls

**DO NOT change minimal context mode significantly** - Parent agents currently depend on concise summaries. Breaking minimal format would break existing workflows.

**DO NOT include raw output in diagnostic mode for successes** - User explicitly wants "only on failures" to control token usage. Diagnostic context adds structure, not raw output.

**DO NOT make Status field overly complex** - Exit code + fixability is sufficient. Avoid tool-specific severity analysis (e.g., "warnings are okay") which creates inconsistency.

**DO NOT create too many predefined contexts** - Keep it simple: minimal, diagnostic. Let parent agents describe their needs naturally. Future expansion can add more contexts if patterns emerge.

### Raw Discoveries Log

- Confirmed: Current devrun is deliberately concise (lines 120-129 in devrun.md)
- Discovered: Parent agents lose critical context (command, exit code, status)
- Learned: Token efficiency is important but information loss undermines decisions
- Verified: User wants "always delegate to devrun" for consistency
- Noted: Implement-plan command needs proceed/stop signals from devrun
- Found: No existing reporting context parameter in devrun agent definition
- Clarified: Diagnostic context should NOT include raw output for successes (only structure)
- Learned: User prefers "reporting context" over "verbosity" - more flexible and semantic

### Implementation Risks

**Backward compatibility:**

- Minimal context mode must remain compatible with existing parent agents
- Any changes to minimal output could break workflows

**Token usage:**

- Diagnostic context adds 50-100 tokens per report
- Must be opt-in to avoid surprising token increases
- Parent agents must be updated to use diagnostic context appropriately

**Consistency:**

- All tools (pytest, pyright, ruff, make) must follow same format
- Status signals must be reliable across tools
- Fixability detection must work consistently

## Implementation Steps

### 1. Add Reporting Context Parameter to devrun.md

**File**: `.agent/kits/devrun/agents/devrun/devrun.md`

**Location**: Add new section after "Your Goal" section (around line 30)

**Add this section**:

```markdown
## Reporting Context Modes

The parent agent can request different types of information in your report by specifying a reporting context in the prompt. The context describes _why_ they need the information, allowing you to tailor your response appropriately.

### Detection

Look for these patterns in the parent's prompt:

- "Execute with diagnostic reporting: [command]" ‚Üí Use **diagnostic context**
- "Execute for CI validation: [command]" ‚Üí Use **diagnostic context**
- "Execute for debugging: [command]" ‚Üí Use **diagnostic context**
- "Execute with minimal reporting: [command]" ‚Üí Use **minimal context**
- "Execute: [command]" (no context specified) ‚Üí Use **minimal context** (default)

### Minimal Context (Default)

Preserve current concise reporting:

**For Successes:**
```

**Summary**: [Brief result in 2-3 sentences with key metrics]

```

**For Failures:**
```

**Summary**: [Brief result statement]
**Details**: [Structured list of issues with locations]

```

Keep output minimal while preserving critical information.

### Diagnostic Context

Provide enhanced structured reporting for deep diagnostics and decision-making:

**For ALL Executions (Success or Failure):**

Always include these fields:

```

**Command**: [exact command executed]
**Exit Code**: [number] ([brief explanation])
**Summary**: [one-line result]
**Details**: [structured information about what was checked/run]
**Status**: [status signal - see below]

```

**Status Signals:**

Determine status based on exit code and fixability:

- **Exit Code 0**: `**Status**: ‚úÖ Safe to proceed`
- **Exit Code 1+ with fixable violations**: `**Status**: üîß Auto-fixable - re-run with --fix`
- **Exit Code 1+ without fixability**: `**Status**: ‚õî Must fix before continuing`
- **Exit Code 2+**: `**Status**: ‚õî Tool error - check configuration`

**Fixability Detection:**

Check tool output for fixability indicators:
- **ruff**: "N fixable with the --fix option"
- **pytest**: Never fixable (code changes required)
- **pyright**: Never fixable (code changes required)
- **make**: Depends on underlying tool

**Details Section Structure:**

**For Successes (Diagnostic):**
- Scope: How many files/tests/modules checked
- Metrics: Time taken, counts, percentages
- Breakdown: For aggregated commands (make all-ci), show each sub-tool

Example:
```

**Details**:

- Tests run: 156
- Passed: 156
- Failed: 0
- Skipped: 0
- Duration: 4.21s

```

**For Failures (Diagnostic):**
- Issue counts and types
- File locations with line numbers
- Fixability assessment
- Suggested next steps

Example:
```

**Details**:

- Tests run: 156
- Passed: 154 (98.7%)
- Failed: 2 (1.3%)
- Duration: 4.18s

**Failures**:

1. tests/test_auth.py::test_login_valid:42
   AssertionError: Expected True, got False
2. tests/test_user.py::test_create:23
   TypeError: Missing required argument 'email'

**Fixability**: Requires code changes (not auto-fixable)

```

**For Aggregated Commands** (make all-ci, make test, etc.) **in Diagnostic Context**:

Always provide breakdown showing each sub-tool:

```

**Breakdown**:
‚úÖ ruff check: 0 violations (47 files)
‚úÖ pyright: 0 errors (32 files)
‚ùå pytest: 2/156 failed (1.3% failure rate)

```

```

**Related Context:**

- Minimal context must remain unchanged to preserve backward compatibility
- Diagnostic context adds ~50-100 tokens but provides critical decision information
- Status field enables parent agents to make proceed/stop decisions

**Success Criteria:**

- Reporting context detection works from prompt patterns
- Minimal context output unchanged from current behavior
- Diagnostic context includes all required fields
- Status signals are consistent across all tools

### 2. Update Tool-Specific Output Templates

**Files to update**:

- `.agent/kits/devrun/docs/devrun/tools/pytest.md`
- `.agent/kits/devrun/docs/devrun/tools/pyright.md`
- `.agent/kits/devrun/docs/devrun/tools/ruff.md`
- `.agent/kits/devrun/docs/devrun/tools/make.md`

**For each tool file, add two sections:**

#### Section 1: Minimal Context Templates (preserve existing)

Keep current output templates as-is under "## Minimal Context Output" heading.

#### Section 2: Diagnostic Context Templates (new)

Add "## Diagnostic Context Output" section with these templates:

**For pytest.md:**

```markdown
## Diagnostic Context Output

### All Tests Passing

**Command**: pytest tests/
**Exit Code**: 0 (all tests passed)
**Summary**: All tests passed
**Details**:

- Tests run: 156
- Passed: 156
- Failed: 0
- Skipped: 0
- Duration: 4.21s
  **Status**: ‚úÖ Safe to proceed

### Partial Failures

**Command**: pytest tests/unit/
**Exit Code**: 1 (test failures detected)
**Summary**: Test failures detected
**Details**:

- Tests run: 156
- Passed: 154 (98.7%)
- Failed: 2 (1.3%)
- Skipped: 0
- Duration: 4.18s

**Failures**:

1. tests/test_auth.py::test_login_valid:42
   AssertionError: Expected True, got False

2. tests/test_user.py::test_create:23
   TypeError: Missing required argument 'email'

**Fixability**: Requires code changes (not auto-fixable)
**Status**: ‚õî Must fix before continuing

### Collection Errors

**Command**: pytest tests/
**Exit Code**: 5 (no tests collected)
**Summary**: Test collection failed
**Details**: No tests found or import errors prevented collection
**Status**: ‚õî Tool error - check test discovery and imports
```

**For pyright.md:**

```markdown
## Diagnostic Context Output

### No Errors

**Command**: pyright src/
**Exit Code**: 0 (no errors found)
**Summary**: Type checking passed
**Details**:

- Files analyzed: 32
- Errors: 0
- Warnings: 0
- Informations: 0
- Duration: 2.4s
  **Status**: ‚úÖ Safe to proceed

### Type Errors Found

**Command**: pyright src/models/
**Exit Code**: 1 (type errors detected)
**Summary**: Type errors detected
**Details**:

- Files analyzed: 8
- Errors: 3
- Warnings: 0
- Informations: 0

**Errors**:

1. src/models/user.py:45:12
   reportAssignmentType: Type "str | None" cannot be assigned to "str"

2. src/models/auth.py:89:20
   reportArgumentType: Argument type "int" incompatible with parameter type "str"

3. src/models/db.py:102:5
   reportReturnType: Return type "None" incompatible with declared type "User"

**Fixability**: Requires code changes (not auto-fixable)
**Status**: ‚õî Must fix before continuing
```

**For ruff.md:**

```markdown
## Diagnostic Context Output

### No Violations

**Command**: ruff check src/
**Exit Code**: 0 (no violations found)
**Summary**: All lint checks passed
**Details**:

- Files checked: 47
- Violations: 0
- Duration: 0.8s
  **Status**: ‚úÖ Safe to proceed

### Fixable Violations

**Command**: ruff check src/
**Exit Code**: 1 (violations found)
**Summary**: Lint violations detected (auto-fixable)
**Details**:

- Files checked: 47
- Violations: 12
- Fixable: 12 (100%)

**Violations**:

- F841: Local variable assigned but never used (8 files)
- I001: Import block is unsorted (4 files)

**Fixability**: All violations auto-fixable with `ruff check --fix`
**Status**: üîß Auto-fixable - re-run with --fix

### Non-Fixable Violations

**Command**: ruff check src/
**Exit Code**: 1 (violations found)
**Summary**: Lint violations detected
**Details**:

- Files checked: 47
- Violations: 5
- Fixable: 0

**Violations**:

1. src/auth.py:123:5
   E501: Line too long (120 > 100 characters)

2. src/models/user.py:45:9
   N806: Variable in function should be lowercase

**Fixability**: Requires manual code changes
**Status**: ‚õî Must fix before continuing
```

**For make.md:**

```markdown
## Diagnostic Context Output

### All Sub-commands Passing

**Command**: make all-ci
**Exit Code**: 0 (all checks passed)
**Summary**: All CI checks passed

**Breakdown**:
‚úÖ ruff check: 0 violations (47 files)
‚úÖ ruff format --check: All files formatted
‚úÖ pyright: 0 errors (32 files)
‚úÖ pytest: 156/156 passed (4.2s)

**Status**: ‚úÖ Safe to proceed

### Partial Failure

**Command**: make test
**Exit Code**: 1 (pytest failed)
**Summary**: Some checks failed

**Breakdown**:
‚úÖ ruff check: 0 violations (47 files)
‚úÖ pyright: 0 errors (32 files)
‚ùå pytest: 2/156 failed (1.3% failure rate)

**Details**: See pytest failure details above

**Status**: ‚õî Must fix before continuing

### With Auto-Fixable Issues

**Command**: make lint
**Exit Code**: 1 (ruff found violations)
**Summary**: Lint violations detected (auto-fixable)

**Breakdown**:
‚ùå ruff check: 12 violations (all fixable)
‚úÖ ruff format --check: All files formatted

**Details**: 12 violations in 8 files, all auto-fixable

**Fixability**: Run `make lint-fix` or `ruff check --fix`
**Status**: üîß Auto-fixable - re-run with --fix
```

**Related Context:**

- Templates provide concrete examples for devrun to follow
- Each tool has specific exit code meanings
- Fixability detection varies by tool (ruff reports it, pytest never fixable)
- Breakdown section only appears for make/aggregated commands

**Success Criteria:**

- Each tool has both minimal and diagnostic templates
- Templates show realistic output examples
- Fixability correctly represented per tool
- Status signals match exit code + fixability rules

### 3. Update Exit Code Documentation

**File**: `.agent/kits/devrun/agents/devrun/devrun.md`

**Location**: Add new section after "Reporting Context Modes" section

**Add this section**:

```markdown
## Exit Code Reference

Understanding exit codes is critical for determining status signals in diagnostic mode.

### Common Exit Codes Across Tools

**Exit Code 0**: Success / No issues found

- All checks passed
- Status: ‚úÖ Safe to proceed

**Exit Code 1**: Failures / Violations found

- Tests failed, type errors found, lint violations detected
- Check fixability to determine status:
  - If fixable: üîß Auto-fixable
  - If not fixable: ‚õî Must fix before continuing

**Exit Code 2**: Tool error / Misconfiguration

- Invalid arguments, configuration errors, internal tool errors
- Status: ‚õî Tool error - check configuration

### Tool-Specific Exit Codes

**pytest:**

- 0: All tests passed
- 1: Test failures
- 2: Test execution interrupted
- 3: Internal error
- 4: pytest command line usage error
- 5: No tests collected

**pyright:**

- 0: No errors
- 1: Type errors found

**ruff:**

- 0: No violations
- 1: Violations found (check fixable count)

**make:**

- 0: All commands succeeded
- 1: One or more commands failed
- 2: Make itself encountered error

Always include exit code with brief explanation in diagnostic mode.
```

**Related Context:**

- Exit codes determine base status signal
- Tool-specific codes help diagnose issues
- pytest has complex exit code system (5 different failure modes)

**Success Criteria:**

- Exit codes documented for all supported tools
- Status signal mapping clear
- Tool-specific codes explained

### 4. Update Parent Agent: implement-plan

**File**: `.claude/commands/workstack/workstack-implement-plan.md`

**Location**: Find the "Step 9: Final Verification" section (around line 217)

**Change from**:

```markdown
### Step 9: Final Verification

After completing all implementation steps:

1. **Check for project documentation** at repository root:
   - Look for `CLAUDE.md` or `AGENTS.md` files
   - If found, read these files for CI/testing instructions
   - Follow any specific commands or workflows documented there

2. **Run project-specific CI checks**:
   - If documentation specifies CI commands, use those
   - Otherwise, run common checks if tools are available:
     - Linting: `ruff check .` or equivalent
     - Type checking: `pyright` or equivalent
     - Tests: `pytest` or equivalent
     - Formatting: `ruff format .` or equivalent
```

**Change to**:

```markdown
### Step 9: Final Verification

After completing all implementation steps:

1. **Check for project documentation** at repository root:
   - Look for `CLAUDE.md` or `AGENTS.md` files
   - If found, read these files for CI/testing instructions
   - Follow any specific commands or workflows documented there

2. **Run project-specific CI checks using devrun agent**:

   Delegate to devrun with diagnostic reporting for detailed diagnostics:
```

Task(
subagent_type="devrun",
description="Run CI checks",
prompt="Execute with diagnostic reporting: make all-ci"
)

```

If documentation specifies different commands, use those instead.

3. **Interpret devrun results**:

- **‚úÖ Safe to proceed**: All checks passed, implementation complete
- **üîß Auto-fixable**: Re-run with --fix flag via devrun
- **‚õî Must fix**: Review failure details and fix issues before completing

4. **For failures**: Return to relevant implementation steps to fix issues
```

**Related Context:**

- Implement-plan is primary consumer of devrun
- Needs diagnostic mode for final verification diagnostics
- Must understand status signals to make proceed/stop decisions
- Always uses diagnostic to get full breakdown of CI results

**Success Criteria:**

- Implement-plan delegates to devrun instead of direct Bash
- Uses diagnostic mode for final verification
- Interprets status signals correctly
- Clear workflow for handling different statuses

### 5. Add Examples to devrun.md

**File**: `.agent/kits/devrun/agents/devrun/devrun.md`

**Location**: Add new section at end of file (before any closing notes)

**Add this section**:

```markdown
## Example Interactions

### Example 1: Minimal Context (Default)

**Parent prompt**: "Execute: pytest tests/"

**Your minimal response**:
```

**Summary**: All tests passed (156 tests in 4.2s)

```

### Example 2: Diagnostic Context - Success

**Parent prompt**: "Execute with diagnostic reporting: make all-ci"

**Your diagnostic response**:
```

**Command**: make all-ci
**Exit Code**: 0 (all checks passed)
**Summary**: All CI checks passed

**Breakdown**:
‚úÖ ruff check: 0 violations (47 files)
‚úÖ ruff format --check: All files formatted
‚úÖ pyright: 0 errors (32 files)
‚úÖ pytest: 156/156 passed (4.2s)

**Status**: ‚úÖ Safe to proceed

```

### Example 3: Diagnostic Context - Auto-Fixable Failure

**Parent prompt**: "Execute with diagnostic reporting: ruff check src/"

**Your diagnostic response**:
```

**Command**: ruff check src/
**Exit Code**: 1 (violations found)
**Summary**: Lint violations detected (auto-fixable)

**Details**:

- Files checked: 47
- Violations: 12
- Fixable: 12 (100%)

**Violations**:

- F841: Local variable assigned but never used (8 files)
- I001: Import block is unsorted (4 files)

**Fixability**: All violations auto-fixable with `ruff check --fix`
**Status**: üîß Auto-fixable - re-run with --fix

```

### Example 4: Diagnostic Context - Must Fix

**Parent prompt**: "Execute with diagnostic reporting: pytest tests/"

**Your diagnostic response**:
```

**Command**: pytest tests/
**Exit Code**: 1 (test failures detected)
**Summary**: Test failures detected

**Details**:

- Tests run: 156
- Passed: 154 (98.7%)
- Failed: 2 (1.3%)
- Duration: 4.18s

**Failures**:

1. tests/test_auth.py::test_login_valid:42
   AssertionError: Expected True, got False

2. tests/test_user.py::test_create:23
   TypeError: Missing required argument 'email'

**Fixability**: Requires code changes (not auto-fixable)
**Status**: ‚õî Must fix before continuing

```

### Example 5: Minimal Context - Failure

**Parent prompt**: "Execute: pytest tests/"

**Your minimal response**:
```

**Summary**: Test failures detected (2/156 tests failed)

**Failures**:

- tests/test_auth.py::test_login_valid:42
- tests/test_user.py::test_create:23

```

(Note: Minimal context still shows critical failure info, just less diagnostic)
```

**Related Context:**

- Examples help devrun understand expected output format
- Shows contrast between minimal and diagnostic modes
- Covers common scenarios: success, auto-fixable, must-fix
- Minimal context examples preserve current concise behavior

**Success Criteria:**

- Examples cover both reporting context modes
- All status signal types represented
- Realistic tool output shown
- Clear difference between minimal and diagnostic

## Testing Strategy

### Manual Testing Checklist

After implementation, test these scenarios:

1. **Minimal context (default)**:
   - Run: `/ensure-ci` (which should use devrun)
   - Verify: Output is concise, similar to current behavior
   - Verify: No breaking changes to existing format

2. **Diagnostic context - success**:
   - Manually invoke devrun with "Execute with diagnostic reporting: make all-ci"
   - Verify: Command, exit code, breakdown, status all present
   - Verify: Status is ‚úÖ Safe to proceed

3. **Diagnostic context - auto-fixable**:
   - Introduce ruff violation (unused variable)
   - Run: devrun with diagnostic reporting on `ruff check`
   - Verify: Status is üîß Auto-fixable
   - Verify: Fixability message includes fix command

4. **Diagnostic context - must fix**:
   - Introduce test failure
   - Run: devrun with diagnostic reporting on `pytest`
   - Verify: Status is ‚õî Must fix
   - Verify: Failure details include file locations

5. **Implement-plan integration**:
   - Run: `/workstack:implement-plan` on a simple plan
   - Verify: Final verification step uses devrun with diagnostic
   - Verify: Parent agent correctly interprets status signals

### Edge Cases to Test

- **No reporting context specified**: Defaults to minimal mode
- **Malformed command**: Exit code 2, tool error status
- **Mixed fixability**: Some fixable, some not (mark as must-fix)
- **Make with partial failure**: Breakdown shows which sub-tool failed
- **Empty test collection**: pytest exit 5, tool error status

## Files Modified

1. `.agent/kits/devrun/agents/devrun/devrun.md` - Core agent instructions (~150 lines added)
2. `.agent/kits/devrun/docs/devrun/tools/pytest.md` - Add diagnostic templates (~60 lines)
3. `.agent/kits/devrun/docs/devrun/tools/pyright.md` - Add diagnostic templates (~50 lines)
4. `.agent/kits/devrun/docs/devrun/tools/ruff.md` - Add diagnostic templates (~60 lines)
5. `.agent/kits/devrun/docs/devrun/tools/make.md` - Add diagnostic breakdown examples (~50 lines)
6. `.claude/commands/workstack/workstack-implement-plan.md` - Update final verification (~20 lines changed)

## Success Criteria

‚úÖ Reporting context parameter system implemented with minimal (default) and diagnostic modes
‚úÖ Minimal context preserves current concise behavior (backward compatible)
‚úÖ Diagnostic context includes: Command, Exit Code, Summary, Details, Status
‚úÖ Status signals based on exit code + fixability check
‚úÖ Raw output only shown on failures (not in diagnostic successes)
‚úÖ All tool templates updated with diagnostic examples
‚úÖ Implement-plan delegates to devrun with diagnostic reporting
‚úÖ Exit code documentation complete
‚úÖ Examples show both reporting context modes
‚úÖ Manual testing passes all scenarios

---

## Progress Tracking

**Current Status:** Complete

**Last Updated:** 2025-11-14

### Implementation Progress

- [x] Step 1: Add reporting context parameter to devrun.md
- [x] Step 2: Update tool-specific output templates
- [x] Step 3: Update exit code documentation
- [x] Step 4: Update parent agent: implement-plan
- [x] Step 5: Add examples to devrun.md

### Overall Progress

**Steps Completed:** 5 / 5
